# Module 4: Vision-Language-Action (VLA)

Welcome to the final module of our textbook, focusing on Vision-Language-Action (VLA) systems. This module explores how robots can understand voice commands, plan complex tasks using language models, and execute actions safely and effectively.

## Chapters in this Module

- [Chapter 4.1: Voice to Action](./chapter-4.1.md)
- [Chapter 4.2: Language-Based Planning](./chapter-4.2.md)
- [Chapter 4.3: Capstone â€“ The Autonomous Humanoid](./chapter-4.3.md)

## Learning Objectives

By the end of this module, you will be able to:
- Implement speech recognition and voice command processing for robots
- Use large language models for task planning and decomposition
- Design safe and effective Vision-Language-Action systems
- Understand the integration challenges of multimodal AI systems
- Consider safety and ethical implications of autonomous humanoid robots