"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[364],{8453:(n,i,e)=>{e.d(i,{R:()=>t,x:()=>a});var s=e(6540);const l={},r=s.createContext(l);function t(n){const i=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function a(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:t(n.components),s.createElement(r.Provider,{value:i},n.children)}},9878:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var s=e(4848),l=e(8453);const r={},t="Chapter 4.2: Language-Based Planning",a={id:"module-4/chapter-4.2",title:"Chapter 4.2: Language-Based Planning",description:"Introduction",source:"@site/docs/module-4/chapter-4.2.md",sourceDirName:"module-4",slug:"/module-4/chapter-4.2",permalink:"/hackathon-physical-ai-humanoid-textbook/module-4/chapter-4.2",draft:!1,unlisted:!1,editUrl:"https://github.com/mudasiralilaghari/hackathon-physical-ai-humanoid-textbook/tree/main/docs/module-4/chapter-4.2.md",tags:[],version:"current",frontMatter:{},sidebar:"textbookSidebar",previous:{title:"Chapter 4.1: Voice to Action",permalink:"/hackathon-physical-ai-humanoid-textbook/module-4/chapter-4.1"},next:{title:"Chapter 4.3: Capstone \u2013 The Autonomous Humanoid",permalink:"/hackathon-physical-ai-humanoid-textbook/module-4/chapter-4.3"}},o={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Using LLMs for Task Planning",id:"using-llms-for-task-planning",level:2},{value:"Large Language Models in Robotics",id:"large-language-models-in-robotics",level:3},{value:"LLM Capabilities",id:"llm-capabilities",level:4},{value:"Robotics-Specific Applications",id:"robotics-specific-applications",level:4},{value:"LLM Integration Challenges",id:"llm-integration-challenges",level:3},{value:"Grounding Problem",id:"grounding-problem",level:4},{value:"Planning Challenges",id:"planning-challenges",level:4},{value:"LLM Architectures for Robotics",id:"llm-architectures-for-robotics",level:3},{value:"Specialized Models",id:"specialized-models",level:4},{value:"Model Integration Approaches",id:"model-integration-approaches",level:4},{value:"Breaking Commands into Actions",id:"breaking-commands-into-actions",level:2},{value:"Hierarchical Task Decomposition",id:"hierarchical-task-decomposition",level:3},{value:"Task Structure",id:"task-structure",level:4},{value:"Decomposition Strategies",id:"decomposition-strategies",level:4},{value:"Action Representation",id:"action-representation",level:3},{value:"Action Spaces",id:"action-spaces",level:4},{value:"Action Libraries",id:"action-libraries",level:4},{value:"Planning Algorithms",id:"planning-algorithms",level:3},{value:"Classical Planning Integration",id:"classical-planning-integration",level:4},{value:"LLM-Enhanced Planning",id:"llm-enhanced-planning",level:4},{value:"Context and Memory",id:"context-and-memory",level:3},{value:"World Modeling",id:"world-modeling",level:4},{value:"Memory Systems",id:"memory-systems",level:4},{value:"Planning Considerations",id:"planning-considerations",level:2},{value:"Safety and Feasibility",id:"safety-and-feasibility",level:3},{value:"Safety Constraints",id:"safety-constraints",level:4},{value:"Feasibility Checking",id:"feasibility-checking",level:4},{value:"Uncertainty Management",id:"uncertainty-management",level:3},{value:"Environmental Uncertainty",id:"environmental-uncertainty",level:4},{value:"Planning Under Uncertainty",id:"planning-under-uncertainty",level:4},{value:"Human-Robot Collaboration",id:"human-robot-collaboration",level:3},{value:"Intent Understanding",id:"intent-understanding",level:4},{value:"Communication and Feedback",id:"communication-and-feedback",level:4},{value:"Implementation Strategies",id:"implementation-strategies",level:2},{value:"LLM Integration Patterns",id:"llm-integration-patterns",level:3},{value:"Direct Integration",id:"direct-integration",level:4},{value:"Hybrid Approaches",id:"hybrid-approaches",level:4},{value:"Planning Architectures",id:"planning-architectures",level:3},{value:"Hierarchical Architecture",id:"hierarchical-architecture",level:4},{value:"Reactive Architecture",id:"reactive-architecture",level:4},{value:"Validation and Verification",id:"validation-and-verification",level:3},{value:"Plan Validation",id:"plan-validation",level:4},{value:"Continuous Learning",id:"continuous-learning",level:4},{value:"Learning Summary",id:"learning-summary",level:2},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2}];function d(n){const i={h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"chapter-42-language-based-planning",children:"Chapter 4.2: Language-Based Planning"}),"\n",(0,s.jsx)(i.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(i.p,{children:"In this chapter, we'll explore how large language models (LLMs) can be used for task planning in robotics. Language-based planning involves using natural language understanding and reasoning capabilities of LLMs to decompose complex commands into executable robotic actions."}),"\n",(0,s.jsx)(i.h2,{id:"using-llms-for-task-planning",children:"Using LLMs for Task Planning"}),"\n",(0,s.jsx)(i.h3,{id:"large-language-models-in-robotics",children:"Large Language Models in Robotics"}),"\n",(0,s.jsx)(i.h4,{id:"llm-capabilities",children:"LLM Capabilities"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Reasoning"}),": LLMs can perform logical reasoning and problem-solving"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Knowledge"}),": Access to vast amounts of world knowledge and common sense"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Instruction Following"}),": Ability to follow complex, multi-step instructions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Context Understanding"}),": Understanding of context and relationships"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"robotics-specific-applications",children:"Robotics-Specific Applications"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Task Decomposition"}),": Breaking complex goals into simpler subtasks"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Action Sequencing"}),": Determining the order of actions to achieve goals"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Constraint Handling"}),": Understanding physical and safety constraints"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Refinement"}),": Adjusting plans based on environmental feedback"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"llm-integration-challenges",children:"LLM Integration Challenges"}),"\n",(0,s.jsx)(i.h4,{id:"grounding-problem",children:"Grounding Problem"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Physical Grounding"}),": Connecting abstract language to physical reality"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Embodied Understanding"}),": Understanding how language relates to physical actions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Perceptual Grounding"}),": Connecting language to sensor data"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Action Grounding"}),": Mapping language to specific robot actions"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"planning-challenges",children:"Planning Challenges"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Temporal Reasoning"}),": Understanding time relationships and sequences"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Spatial Reasoning"}),": Understanding spatial relationships and navigation"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Causal Reasoning"}),": Understanding cause-and-effect relationships"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Uncertainty Handling"}),": Reasoning under uncertain conditions"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"llm-architectures-for-robotics",children:"LLM Architectures for Robotics"}),"\n",(0,s.jsx)(i.h4,{id:"specialized-models",children:"Specialized Models"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Vision-Language Models"}),": Models that understand both visual and textual input"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Multimodal Transformers"}),": Models that process multiple types of input"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Embodied AI Models"}),": Models specifically trained for embodied tasks"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Robot-Specific Fine-Tuning"}),": Adapting general models to robotics tasks"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"model-integration-approaches",children:"Model Integration Approaches"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Chain-of-Thought"}),": Step-by-step reasoning for complex planning"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Few-Shot Learning"}),": Learning from examples provided at runtime"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Prompt Engineering"}),": Crafting prompts to guide model behavior"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Tool Integration"}),": Connecting LLMs to external tools and systems"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"breaking-commands-into-actions",children:"Breaking Commands into Actions"}),"\n",(0,s.jsx)(i.h3,{id:"hierarchical-task-decomposition",children:"Hierarchical Task Decomposition"}),"\n",(0,s.jsx)(i.h4,{id:"task-structure",children:"Task Structure"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"High-Level Goals"}),": Abstract goals expressed in natural language"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Subtask Decomposition"}),": Breaking goals into manageable components"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Primitive Actions"}),": Basic robot capabilities that can be executed"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Action Sequences"}),": Ordered sequences of primitive actions"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"decomposition-strategies",children:"Decomposition Strategies"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Functional Decomposition"}),": Breaking by function (navigate, manipulate, etc.)"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Temporal Decomposition"}),": Breaking by time sequence"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Spatial Decomposition"}),": Breaking by location or area"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Object-Centered"}),": Breaking by objects involved in the task"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"action-representation",children:"Action Representation"}),"\n",(0,s.jsx)(i.h4,{id:"action-spaces",children:"Action Spaces"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Symbolic Actions"}),": High-level, abstract action descriptions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Parameterized Actions"}),": Actions with specific parameters"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Continuous Actions"}),": Low-level control commands"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Hybrid Representations"}),": Combinations of different action types"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"action-libraries",children:"Action Libraries"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Predefined Actions"}),": Fixed set of available robot capabilities"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Composable Actions"}),": Actions that can be combined flexibly"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Parameterizable Actions"}),": Actions with configurable parameters"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Learned Actions"}),": Actions learned through experience"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"planning-algorithms",children:"Planning Algorithms"}),"\n",(0,s.jsx)(i.h4,{id:"classical-planning-integration",children:"Classical Planning Integration"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"STRIPS Representation"}),": State, Action, and Goal representation"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"PDDL Integration"}),": Planning Domain Definition Language"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"State Space Search"}),": Searching through possible action sequences"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Heuristic Functions"}),": Guiding search with domain knowledge"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"llm-enhanced-planning",children:"LLM-Enhanced Planning"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Generation"}),": LLMs generate potential action sequences"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Evaluation"}),": LLMs evaluate plan feasibility and safety"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Refinement"}),": LLMs improve and optimize generated plans"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Execution Monitoring"}),": LLMs monitor execution and suggest corrections"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"context-and-memory",children:"Context and Memory"}),"\n",(0,s.jsx)(i.h4,{id:"world-modeling",children:"World Modeling"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Current State"}),": Maintaining understanding of current robot state"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Environmental State"}),": Understanding the current environment"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Goal State"}),": Understanding the desired end state"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Temporal Context"}),": Understanding time relationships"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"memory-systems",children:"Memory Systems"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Short-Term Memory"}),": Information relevant to current task"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Long-Term Memory"}),": Persistent knowledge about the world"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Episodic Memory"}),": Memories of past interactions and tasks"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Semantic Memory"}),": General knowledge and facts"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"planning-considerations",children:"Planning Considerations"}),"\n",(0,s.jsx)(i.h3,{id:"safety-and-feasibility",children:"Safety and Feasibility"}),"\n",(0,s.jsx)(i.h4,{id:"safety-constraints",children:"Safety Constraints"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Physical Safety"}),": Ensuring actions don't cause harm"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Operational Safety"}),": Maintaining robot operational integrity"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Environmental Safety"}),": Protecting the environment and objects"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Human Safety"}),": Ensuring human safety during interaction"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"feasibility-checking",children:"Feasibility Checking"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Physical Feasibility"}),": Checking if actions are physically possible"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Kinematic Feasibility"}),": Ensuring robot can physically perform actions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Dynamic Feasibility"}),": Considering robot dynamics and constraints"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Resource Feasibility"}),": Checking available resources and time"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"uncertainty-management",children:"Uncertainty Management"}),"\n",(0,s.jsx)(i.h4,{id:"environmental-uncertainty",children:"Environmental Uncertainty"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Partial Observability"}),": Working with incomplete environmental information"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Dynamic Environments"}),": Handling changing environmental conditions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Sensor Uncertainty"}),": Managing noisy and uncertain sensor data"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Predictive Uncertainty"}),": Uncertainty about future states"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"planning-under-uncertainty",children:"Planning Under Uncertainty"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Probabilistic Planning"}),": Planning with probability distributions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Contingency Planning"}),": Planning for multiple possible outcomes"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Reactive Planning"}),": Adjusting plans based on new information"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Robust Planning"}),": Creating plans that work under various conditions"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"human-robot-collaboration",children:"Human-Robot Collaboration"}),"\n",(0,s.jsx)(i.h4,{id:"intent-understanding",children:"Intent Understanding"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Implicit Goals"}),": Understanding goals not explicitly stated"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Social Conventions"}),": Following social norms and expectations"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Collaborative Intent"}),": Understanding collaborative task structures"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Preference Learning"}),": Learning user preferences over time"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"communication-and-feedback",children:"Communication and Feedback"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Explanation"}),": Explaining planned actions to users"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Progress Reporting"}),": Keeping users informed of execution status"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Request Clarification"}),": Asking for clarification when uncertain"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Suggestion and Correction"}),": Offering alternatives and accepting corrections"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"implementation-strategies",children:"Implementation Strategies"}),"\n",(0,s.jsx)(i.h3,{id:"llm-integration-patterns",children:"LLM Integration Patterns"}),"\n",(0,s.jsx)(i.h4,{id:"direct-integration",children:"Direct Integration"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"API Calls"}),": Direct calls to LLM APIs for planning"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Real-Time Processing"}),": LLM processing during robot operation"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Prompt-Based Planning"}),": Using prompts to guide planning"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Response Parsing"}),": Extracting structured plans from LLM responses"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"hybrid-approaches",children:"Hybrid Approaches"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"LLM + Classical Planning"}),": Combining LLM reasoning with classical planners"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"LLM + Reinforcement Learning"}),": Combining reasoning with learning"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"LLM + Simulation"}),": Using simulation to validate LLM plans"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Multi-Model Integration"}),": Combining multiple AI models"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"planning-architectures",children:"Planning Architectures"}),"\n",(0,s.jsx)(i.h4,{id:"hierarchical-architecture",children:"Hierarchical Architecture"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"High-Level Reasoning"}),": LLM handles high-level planning"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Mid-Level Coordination"}),": Classical systems coordinate subtasks"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Low-Level Execution"}),": Direct robot control and execution"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Feedback Loops"}),": Information flow between levels"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"reactive-architecture",children:"Reactive Architecture"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Event-Driven Planning"}),": Planning triggered by events or conditions"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Continuous Monitoring"}),": Monitoring environment and plan execution"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Adaptation"}),": Adapting plans based on new information"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Fallback Procedures"}),": Predefined responses to common failures"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"validation-and-verification",children:"Validation and Verification"}),"\n",(0,s.jsx)(i.h4,{id:"plan-validation",children:"Plan Validation"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simulation Testing"}),": Testing plans in simulation before execution"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Safety Checking"}),": Verifying plans meet safety requirements"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Constraint Verification"}),": Checking plans satisfy all constraints"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Performance Evaluation"}),": Assessing plan efficiency and effectiveness"]}),"\n"]}),"\n",(0,s.jsx)(i.h4,{id:"continuous-learning",children:"Continuous Learning"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Plan Success Tracking"}),": Monitoring which plans succeed or fail"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Feedback Integration"}),": Incorporating success/failure feedback"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Behavior Adaptation"}),": Adjusting planning based on experience"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Model Improvement"}),": Improving LLM performance through interaction"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"learning-summary",children:"Learning Summary"}),"\n",(0,s.jsx)(i.p,{children:"In this chapter, we've covered:"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsx)(i.li,{children:"LLMs provide reasoning, knowledge, and instruction-following capabilities for robotics"}),"\n",(0,s.jsx)(i.li,{children:"The grounding problem connects abstract language to physical reality"}),"\n",(0,s.jsx)(i.li,{children:"Task decomposition breaks complex commands into executable actions"}),"\n",(0,s.jsx)(i.li,{children:"Action representation involves symbolic, parameterized, and continuous action spaces"}),"\n",(0,s.jsx)(i.li,{children:"Safety and feasibility checking are critical for practical systems"}),"\n",(0,s.jsx)(i.li,{children:"Uncertainty management handles incomplete and changing information"}),"\n",(0,s.jsx)(i.li,{children:"Human-robot collaboration requires intent understanding and communication"}),"\n",(0,s.jsx)(i.li,{children:"Implementation strategies include direct integration and hybrid approaches"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsx)(i.li,{children:"What is the grounding problem in language-based robotics?"}),"\n",(0,s.jsx)(i.li,{children:"Explain the difference between symbolic and parameterized action representations."}),"\n",(0,s.jsx)(i.li,{children:"What are the main challenges of using LLMs for robotics planning?"}),"\n",(0,s.jsx)(i.li,{children:"How can uncertainty be managed in language-based planning systems?"}),"\n",(0,s.jsx)(i.li,{children:"What safety considerations are important for LLM-based robotic planning?"}),"\n"]})]})}function h(n={}){const{wrapper:i}={...(0,l.R)(),...n.components};return i?(0,s.jsx)(i,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);